The algorithms described so far are agnostic to the underlying motion planner.
Depending upon the model of the application domain, different motion planning primitives might be appropriate. For planar environments with disk robot pickers~(similar to delta robots), recent work~\cite{kirkpatrick2016characterizing} characterizes the optimal two-disk coordinated motions. The current implementation uses a general multi-robot motion planning framework \drrtstar~\cite{Dobson:2017aa} for dual-arm coordinated planning.

% It should be noted that sometimes such motion plans might not be found either because no such solution exists, or because of a limited time budget. In such cases the edge costs should either be set of some arbitrarily large value, or removed altogether. 

In practice the cost of generating and evaluating two-arm motions can dominate the overall running time of the algorithm, when compared to the combinatorial ingredients that discover the high-level plan, i.e., execution order and and arm assignment. Even though \algo reduces this, further improvements can be made with lazy evaluation. 

\begin{wrapfigure}{r}{0.6\textwidth}
  \vspace{-0.1in}
  \begin{minipage}{0.6\textwidth}
  \vspace{0pt} 
  \begin{algorithm}[H]
  \caption{{\tt Lazy\_Evaluation}$ (\mathtt{ALGO}, \mathcal{H}, \mathtt{MP}) $}
  \label{algo:lazy}
  $ \edges_{\mathtt{b}}\leftarrow\emptyset $;  $ \D \leftarrow \emptyset $\;
  \While{$ \D=\emptyset \land \mathtt{time\_not\_exceeded} $}
  {
  %	$ \mathtt{planner}\leftarrow\mathcal{H} $\;
      $ \scoma\leftarrow \mathtt{ALGO} ( \mathcal{H},   \edges_{\mathtt{b}}  ) $\;
  %	$ \mathtt{planner}\leftarrow\mathtt{MP} $;
%       $ \D \leftarrow \emptyset $\;
      \For{$ \coma_i, \coma_{i\rightarrow{i+1}} \in \scoma$}
      {
          $ \D_i,\D_{i\rightarrow i+1} \leftarrow \mathtt{MP}(\coma_i), \mathtt{MP}( \coma_{i\rightarrow{i+1}} ) $\;
          $ \D\leftarrow (\D,\D_i,\D_{i\rightarrow i+1} ) $\;
          \If{$ \D_i = \emptyset $}
          {
              $ \edges_{\mathtt{b}} \leftarrow \edges_{\mathtt{b}}\cup \{\coma_i\}$; $ \D \leftarrow \emptyset$\;
          }
          \If{$ \D_{i\rightarrow i+1} = \emptyset $}
          {
              $ \edges_{\mathtt{b}} \leftarrow \edges_{\mathtt{b}}\cup \{\coma_{i\rightarrow{i+1}}\}$; $\D \leftarrow \emptyset $\;
          }
          \lIf{$ \D=\emptyset $}
          {
          $\mathbf{break}$
          }
      }
  }
  $\mathbf{return}\ D$
  \end{algorithm}
  \end{minipage}
  \vspace{-0.35in}
\end{wrapfigure}

% \kiril{Are we referring to the correct paper here? }. 
% This heuristic corresponds to the pre-processed shortest path costs over underlying roadmaps. 
% \kiril{I suggest to replace this sentence with a high-level description omitting the term "underlying roadmaps": "This heuristic corresponds to pre-processed lower estimates of the shortest-path costs for the two arms."}
% The online part of the estimate is tantamount to a simple look-up. 

\noindent\textbf{Lazy Evaluation}: Recent work~\cite{shome2017improving} introduces heuristics for $ \drrtstar $, which pre-process estimates of the shortest path costs for the arms. Dual-arm rearrangement can be significantly sped up if the motion planning queries are replaced with look-ups of such heuristics. Once a candidate $ \scoma $ is obtained, motion planning can evaluate the solution $ \trajset(\scoma) $. If this fails, the algorithm tries other sequences. 
% \kiril{In line 8 of the algorithm, the first "$D$" in the curly brackets is redundant, right?}


The algorithm Algo \ref{algo:lazy} takes as input the algorithm $ \mathtt{ALGO} $, a heuristic $ \mathcal{H} $, and a motion planner $ \mathtt{MP} $. $ \edges_{\mathtt{b}}$ keeps track of the blocked edges. The process keeps generating candidate solutions using the $ \mathtt{ALGO} $ (Line 3). Line 5 motion plans over the candidate solution, and appends to the result (Line 6). Any failures are recorded in  $ \edges_{\mathtt{b}}$ (Lines 8,10), and inform subsequent runs of $ \mathtt{ALGO} $.


\noindent\textbf{Completeness}: 
% The heuristic versions would be an approximation of the original optimization guarantees of the algorithms. It should be noted that this framework can be used with all the dual-arm approaches ie., exhaustive search, MILP and \algo. 
The lazy variants give up on optimality for the sake of efficiency but given enough retries the algorithms will eventually solve every problem that {\tt ALGO} can. Since the motion planning happens in the order of execution, the object non-interactivity assumption is relaxed.

\noindent\textbf{Smoothing}: 
% The solutions obtained out of the methods adhere to the defined synchronization assumptions of the problem. 
Applying velocity tuning over the solution trajectories for the individual arms relaxes the synchronization assumption
by minimizing any waits that might be a by-product of the synchronization. 
Smoothing does not change the maximum of distances, only improves execution time. Indications that the smoothed variants of the synchronous solutions do not provide significant savings in execution time are included in the Appendix for the interested reader.

It should be noted that in an iterative version of \algo, in order to explore variations in $ \scomaset^* $ if failures occur in finding $\tour$, some edges need to be temporarily blocked on $ \scomaset^* $. The search structures can also be augmented with {\tt NO\_ACT} tasks, for possible $\coma$ where one of the arms do not move. 
% This effectively includes single arm solutions in the search as well.

